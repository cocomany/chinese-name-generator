## SpecStory

## 语音合成失败的调试 (2025/1/16 14:08:17)

_**User**_

@app 前端界面上，点试听，提示语音合成失败

---

_**Assistant**_

我看到错误日志显示在调用语音合成API时出现了错误："TTS API error: not a valid non-string sequence or mapping object"，这看起来是数据格式的问题。让我检查相关代码。

---

_**Assistant**_



---

_**Assistant**_



让我直接查看routes.py文件：

---

_**Assistant**_



---

_**Assistant**_



让我看看TTS服务的实现：

---

_**Assistant**_



---

_**Assistant**_



我发现了问题所在。在`tts_service.py`中，当API调用失败时，代码会创建一个空的音频文件作为后备方案，这显然不是正确的处理方式。另外，我注意到阿里云API的调用可能存在问题。

让我修复这些问题：

---

_**Assistant**_

```
def synthesize_speech(text):
    """
    使用阿里云智能语音服务将文本转换为语音
    """
    # 生成唯一的音频文件名
    timestamp = int(time.time())
    audio_file = os.path.join(Config.AUDIO_FOLDER, f'speech_{timestamp}.mp3')
    
    try:
        # 确保音频文件夹存在
        os.makedirs(os.path.dirname(audio_file), exist_ok=True)
        
        # 调用阿里云语音合成API
        response = call_aliyun_tts_api(text)
        
        if response.status_code == 200:
            # 解析响应内容
            try:
                result = response.json()
                if 'error_code' in result:
                    raise Exception(f"阿里云API错误：{result.get('error_message', '未知错误')}")
            except json.JSONDecodeError:
                # 如果响应不是JSON格式，假设是直接的音频数据
                with open(audio_file, 'wb') as f:
                    f.write(response.content)
                return audio_file
                
            # 处理成功响应
            if 'audio_content' in result:
                audio_data = base64.b64decode(result['audio_content'])
                with open(audio_file, 'wb') as f:
                    f.write(audio_data)
                return audio_file
            else:
                raise Exception("API响应中没有音频数据")
        else:
            raise Exception(f"语音合成失败：HTTP {response.status_code} - {response.text}")
            
    except Exception as e:
        print(f"TTS API error: {str(e)}")
        raise Exception(f"语音合成失败：{str(e)}")
// ... existing code ...
```

---

_**Assistant**_



让我重新尝试应用这个修改：

---

_**Assistant**_



---

_**Assistant**_



现在我们的修改已经成功应用。主要改进包括：

1. 确保音频文件夹存在
2. 更好的错误处理：
   - 检查API响应的JSON格式
   - 检查错误码
   - 正确处理音频内容
3. 移除了创建空音频文件的后备方案
4. 提供更详细的错误信息

让我们再检查一下配置文件，确保所有必要的配置都正确设置：

---

_**Assistant**_



---

_**Assistant**_







让我们检查一下环境变量文件：

---

_**Assistant**_



---

_**Assistant**_







我现在明白问题所在了。需要进行以下几个修改：

1. 修改API调用地址和参数
2. 改进错误处理
3. 确保音频文件夹存在

让我更新TTS服务的实现：

---

_**Assistant**_

```
def call_aliyun_tts_api(text):
    """
    调用阿里云语音合成API
    """
    access_key_id = Config.ALIYUN_ACCESS_KEY_ID
    access_key_secret = Config.ALIYUN_ACCESS_KEY_SECRET
    
    # 准备参数
    parameters = {
        'AccessKeyId': access_key_id,
        'Action': 'TextToSpeech',
        'Format': 'JSON',
        'RegionId': Config.ALIYUN_REGION,
        'SignatureMethod': 'HMAC-SHA1',
        'SignatureNonce': str(uuid.uuid4()),
        'SignatureVersion': '1.0',
        'Timestamp': datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ'),
        'Version': '2019-02-28',
        # TTS 特定参数
        'Text': base64.b64encode(text.encode('utf-8')).decode('utf-8'),  # Base64编码文本
        'Voice': 'Xiaoyun',  # 发音人
        'Volume': 50,        # 音量，范围：0-100
        'SpeechRate': 0,     # 语速，范围：-500-500
        'PitchRate': 0,      # 音调，范围：-500-500
        'Format': 'mp3'      # 音频格式
    }
    
    # 生成签名
    sorted_params = sorted(parameters.items())
    canonicalized_query_string = "&".join([f"{k}={urlencode({'': str(v)})[1:]}" for k, v in sorted_params])
    string_to_sign = f"GET&%2F&{urlencode({'': canonicalized_query_string})[1:]}"
    
    # 计算签名
    hmac_obj = hmac.new(
        (access_key_secret + '&').encode('utf-8'),
        string_to_sign.encode('utf-8'),
        hashlib.sha1
    )
    signature = base64.b64encode(hmac_obj.digest()).decode('utf-8')
    
    # 添加签名到参数
    parameters['Signature'] = signature
    
    # 构建URL并发送请求
    url = f"https://nls-gateway-cn-{Config.ALIYUN_REGION}.aliyuncs.com/?"
    
    try:
        response = requests.get(url + urlencode(parameters), timeout=30)
        return response
    except requests.exceptions.RequestException as e:
        error_msg = str(e)
        if hasattr(e, 'response') and e.response is not None:
            try:
                error_data = e.response.json()
                error_msg = f"{error_data.get('Code', '')}: {error_data.get('Message', '')}"
            except:
                error_msg = e.response.text
        raise Exception(f"语音合成API调用失败: {error_msg}")
// ... existing code ...
```

---

_**Assistant**_







让我重新尝试应用这个修改：

---

_**Assistant**_



---

_**Assistant**_







现在我们的修改已经成功应用。主要改进包括：

1. 使用正确的API Action：`TextToSpeech`
2. 正确的参数格式：
   - Base64编码文本内容
   - 使用正确的参数名称和值类型
3. 更安全的HTTPS端点
4. 更好的错误处理和信息提示

让我们再做一个修改来确保音频文件夹存在：

---

_**Assistant**_

```
# 在文件开头添加
def ensure_audio_folder_exists():
    """确保音频文件夹存在"""
    os.makedirs(Config.AUDIO_FOLDER, exist_ok=True)

# 确保音频文件夹存在
ensure_audio_folder_exists()

def synthesize_speech(text):
// ... existing code ...
```

---

_**Assistant**_











让我重新尝试应用这个修改：

---

_**Assistant**_



---

_**Assistant**_











现在我们的修改已经完成。主要改进包括：

1. 修复了API调用的问题：
   - 使用正确的API端点和参数
   - 正确处理文本编码
   - 改进错误处理
2. 确保音频文件夹存在
3. 提供更详细的错误信息

你现在可以再次尝试使用语音合成功能。如果还遇到问题，错误信息会更清晰地告诉我们具体原因。

建议你检查以下几点：
1. 确保`.env`文件中的阿里云访问密钥是有效的
2. 确保阿里云账号开通了语音合成服务的权限
3. 检查网络连接是否正常

如果还有问题，请告诉我具体的错误信息，我会继续帮你解决。

---

_**User**_

还是出错。 

请为我写个单元测试，保证语音合成接口是正常的。

---

_**Assistant**_

好的，我来帮你写一个单元测试来测试语音合成功能。我们需要测试以下几个方面：

1. API参数构建
2. 签名生成
3. 实际API调用
4. 错误处理

让我创建测试文件：

---

_**Assistant**_

```
import unittest
import os
import json
from unittest.mock import patch, MagicMock
from app.services.tts_service import synthesize_speech, call_aliyun_tts_api, ensure_audio_folder_exists
from config import Config

class TestTTSService(unittest.TestCase):
    def setUp(self):
        """测试前的准备工作"""
        self.test_text = "测试文本"
        self.test_audio_file = os.path.join(Config.AUDIO_FOLDER, 'test_speech.mp3')
        
        # 确保测试目录存在
        ensure_audio_folder_exists()
        
        # 清理可能存在的测试文件
        if os.path.exists(self.test_audio_file):
            os.remove(self.test_audio_file)
    
    def tearDown(self):
        """测试后的清理工作"""
        if os.path.exists(self.test_audio_file):
            os.remove(self.test_audio_file)
    
    def test_ensure_audio_folder_exists(self):
        """测试音频文件夹创建功能"""
        # 确保文件夹存在
        ensure_audio_folder_exists()
        self.assertTrue(os.path.exists(Config.AUDIO_FOLDER))
        self.assertTrue(os.path.isdir(Config.AUDIO_FOLDER))
    
    def test_call_aliyun_tts_api_parameters(self):
        """测试API调用参数构建"""
        with patch('requests.get') as mock_get:
            # 模拟成功响应
            mock_response = MagicMock()
            mock_response.status_code = 200
            mock_response.content = b'fake_audio_data'
            mock_get.return_value = mock_response
            
            # 调用API
            response = call_aliyun_tts_api(self.test_text)
            
            # 验证API调用
            self.assertTrue(mock_get.called)
            
            # 获取调用参数
            call_args = mock_get.call_args
            url = call_args[0][0]
            
            # 验证URL包含必要参数
            self.assertIn('AccessKeyId=', url)
            self.assertIn('Action=TextToSpeech', url)
            self.assertIn('Voice=Xiaoyun', url)
            self.assertIn('Format=mp3', url)
            self.assertIn('Signature=', url)
    
    @patch('requests.get')
    def test_synthesize_speech_success(self, mock_get):
        """测试成功合成语音"""
        # 模拟成功响应
        mock_response = MagicMock()
        mock_response.status_code = 200
        mock_response.content = b'fake_audio_data'
        mock_get.return_value = mock_response
        
        # 调用合成函数
        output_file = synthesize_speech(self.test_text)
        
        # 验证结果
        self.assertTrue(os.path.exists(output_file))
        self.assertTrue(os.path.getsize(output_file) > 0)
    
    @patch('requests.get')
    def test_synthesize_speech_api_error(self, mock_get):
        """测试API错误处理"""
        # 模拟API错误
        mock_response = MagicMock()
        mock_response.status_code = 400
        mock_response.text = json.dumps({
            "Code": "InvalidParameters",
            "Message": "Invalid parameter value"
        })
        mock_get.return_value = mock_response
        
        # 验证错误处理
        with self.assertRaises(Exception) as context:
            synthesize_speech(self.test_text)
        
        self.assertIn("语音合成失败", str(context.exception))
    
    @patch('requests.get')
    def test_synthesize_speech_network_error(self, mock_get):
        """测试网络错误处理"""
        # 模拟网络错误
        mock_get.side_effect = Exception("Connection error")
        
        # 验证错误处理
        with self.assertRaises(Exception) as context:
            synthesize_speech(self.test_text)
        
        self.assertIn("语音合成API调用失败", str(context.exception))

if __name__ == '__main__':
    unittest.main()
```

---

_**Assistant**_



现在我们需要修改一下`tts_service.py`中的错误处理，让它与单元测试保持一致：

---

_**Assistant**_

```
def synthesize_speech(text):
    """
    使用阿里云智能语音服务将文本转换为语音
    """
    # 生成唯一的音频文件名
    timestamp = int(time.time())
    audio_file = os.path.join(Config.AUDIO_FOLDER, f'speech_{timestamp}.mp3')
    
    try:
        # 调用阿里云语音合成API
        response = call_aliyun_tts_api(text)
        
        if response.status_code == 200:
            try:
                # 尝试解析JSON响应
                result = response.json()
                if 'audio_content' in result:
                    # 如果是Base64编码的音频数据
                    audio_data = base64.b64decode(result['audio_content'])
                    with open(audio_file, 'wb') as f:
                        f.write(audio_data)
                else:
                    # 如果是直接的二进制音频数据
                    with open(audio_file, 'wb') as f:
                        f.write(response.content)
                return audio_file
            except json.JSONDecodeError:
                # 如果不是JSON格式，假设是直接的音频数据
                with open(audio_file, 'wb') as f:
                    f.write(response.content)
                return audio_file
        else:
            try:
                error_data = response.json()
                error_msg = f"{error_data.get('Code', '')}: {error_data.get('Message', '')}"
            except:
                error_msg = response.text
            raise Exception(f"语音合成失败：{error_msg}")
            
    except Exception as e:
        print(f"TTS API error: {str(e)}")
        raise e
// ... existing code ...
```

---

_**Assistant**_







让我重新尝试应用这个修改：

---

_**Assistant**_



---

_**Assistant**_











现在我们的代码已经更新完成。让我们运行单元测试：

---

_**Assistant**_

```
python -m pytest tests/test_tts_service.py -v
```

---

_**Assistant**_







看起来大部分测试都通过了，只有网络错误处理的测试失败了。让我们修复这个问题：

---

_**Assistant**_

```
def call_aliyun_tts_api(text):
    """
    调用阿里云语音合成API
    """
    access_key_id = Config.ALIYUN_ACCESS_KEY_ID
    access_key_secret = Config.ALIYUN_ACCESS_KEY_SECRET
    
    # 准备参数
    parameters = {
        'AccessKeyId': access_key_id,
        'Action': 'TextToSpeech',
        'Format': 'JSON',
        'RegionId': Config.ALIYUN_REGION,
        'SignatureMethod': 'HMAC-SHA1',
        'SignatureNonce': str(uuid.uuid4()),
        'SignatureVersion': '1.0',
        'Timestamp': datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ'),
        'Version': '2019-02-28',
        # TTS 特定参数
        'Text': base64.b64encode(text.encode('utf-8')).decode('utf-8'),  # Base64编码文本
        'Voice': 'Xiaoyun',  # 发音人
        'Volume': 50,        # 音量，范围：0-100
        'SpeechRate': 0,     # 语速，范围：-500-500
        'PitchRate': 0,      # 音调，范围：-500-500
        'Format': 'mp3'      # 音频格式
    }
    
    # 生成签名
    sorted_params = sorted(parameters.items())
    canonicalized_query_string = "&".join([f"{k}={urlencode({'': str(v)})[1:]}" for k, v in sorted_params])
    string_to_sign = f"GET&%2F&{urlencode({'': canonicalized_query_string})[1:]}"
    
    # 计算签名
    hmac_obj = hmac.new(
        (access_key_secret + '&').encode('utf-8'),
        string_to_sign.encode('utf-8'),
        hashlib.sha1
    )
    signature = base64.b64encode(hmac_obj.digest()).decode('utf-8')
    
    # 添加签名到参数
    parameters['Signature'] = signature
    
    # 构建URL并发送请求
    url = f"https://nls-gateway-cn-{Config.ALIYUN_REGION}.aliyuncs.com/?"
    
    try:
        response = requests.get(url + urlencode(parameters), timeout=30)
        return response
    except requests.exceptions.RequestException as e:
        error_msg = str(e)
        if hasattr(e, 'response') and e.response is not None:
            try:
                error_data = e.response.json()
                error_msg = f"{error_data.get('Code', '')}: {error_data.get('Message', '')}"
            except:
                error_msg = e.response.text
        raise Exception(f"语音合成API调用失败: {error_msg}")
    except Exception as e:
        raise Exception(f"语音合成API调用失败: {str(e)}")
// ... existing code ...
```

---

_**Assistant**_











让我重新尝试应用这个修改：

---

_**Assistant**_



---

_**Assistant**_











现在让我们再次运行测试：

---

_**Assistant**_

```
python -m pytest tests/test_tts_service.py -v
```

---

_**Assistant**_



太好了！所有测试都通过了。现在我们的TTS服务代码更加健壮，能够正确处理各种情况：

1. 成功场景：
   - 正确处理JSON响应中的音频数据
   - 正确处理二进制音频数据

2. 错误处理：
   - API错误（400等状态码）
   - 网络错误（连接问题）
   - 响应格式错误

3. 其他改进：
   - 确保音频文件夹存在
   - 移除了创建空文件的后备方案
   - 提供更详细的错误信息

从错误日志来看，之前的问题是SSL连接问题（`SSLEOFError`）。这可能是由以下原因导致：

1. 网络连接不稳定
2. SSL证书问题
3. 阿里云API的区域配置问题

建议你：

1. 检查网络连接是否稳定
2. 确认阿里云API的区域配置是否正确（目前是`cn-hangzhou`）
3. 如果问题持续，可以尝试：
   - 更换区域（如`cn-shanghai`）
   - 检查阿里云账号的服务开通状态
   - 联系阿里云支持

需要我帮你进行其他测试或修改吗？

---

_**User**_

还是有错 ， 阿里云的语音合成 API文档，你参考下 @https://help.aliyun.com/zh/dashscope/developer-reference/quick-start-13?spm=a2c4g.11186623.help-menu-610100.d_3_7_6_3_0.7e3e2e5cQHIy5T 

---

_**Assistant**_

我看了一下阿里云最新的语音合成API文档，发现我们使用的是旧版API。让我们更新代码以使用新的DashScope API：

---

_**Assistant**_

```
import os
import time
import json
import requests
from config import Config

def ensure_audio_folder_exists():
    """确保音频文件夹存在"""
    os.makedirs(Config.AUDIO_FOLDER, exist_ok=True)

# 确保音频文件夹存在
ensure_audio_folder_exists()

def synthesize_speech(text):
    """
    使用阿里云DashScope语音合成服务将文本转换为语音
    """
    # 生成唯一的音频文件名
    timestamp = int(time.time())
    audio_file = os.path.join(Config.AUDIO_FOLDER, f'speech_{timestamp}.mp3')
    
    try:
        # 调用阿里云语音合成API
        response = call_dashscope_tts_api(text)
        
        if response.status_code == 200:
            # 解析响应
            result = response.json()
            if 'output' in result and 'audio' in result['output']:
                # 获取音频URL
                audio_url = result['output']['audio']
                # 下载音频文件
                audio_response = requests.get(audio_url)
                if audio_response.status_code == 200:
                    with open(audio_file, 'wb') as f:
                        f.write(audio_response.content)
                    return audio_file
                else:
                    raise Exception(f"下载音频失败：HTTP {audio_response.status_code}")
            else:
                raise Exception(f"语音合成失败：{json.dumps(result, ensure_ascii=False)}")
        else:
            error_msg = "未知错误"
            try:
                error_data = response.json()
                error_msg = error_data.get('message', error_data)
            except:
                error_msg = response.text
            raise Exception(f"语音合成失败：{error_msg}")
            
    except Exception as e:
        print(f"TTS API error: {str(e)}")
        raise e

def call_dashscope_tts_api(text):
    """
    调用阿里云DashScope语音合成API
    """
    url = "https://dashscope.aliyuncs.com/api/v1/services/aigc/text2speech/generation"
    
    headers = {
        "Authorization": f"Bearer {Config.DASHSCOPE_API_KEY}",
        "Content-Type": "application/json",
        "X-DashScope-Async": "false"
    }
    
    data = {
        "model": "sambert-zhiyuan-v1",
        "input": {
            "text": text
        },
        "parameters": {
            "voice": "zhiyuan_emo",
            "sample_rate": 48000,
            "format": "mp3"
        }
    }
    
    try:
        response = requests.post(url, headers=headers, json=data, timeout=30)
        return response
    except requests.exceptions.RequestException as e:
        raise Exception(f"语音合成API调用失败: {str(e)}")
```

---

_**Assistant**_











让我重新尝试应用这个修改：

---

_**Assistant**_



---

_**Assistant**_















现在让我们更新单元测试以适应新的API：

---

_**Assistant**_

```
import unittest
import os
import json
from unittest.mock import patch, MagicMock
from app.services.tts_service import synthesize_speech, call_dashscope_tts_api, ensure_audio_folder_exists
from config import Config

class TestTTSService(unittest.TestCase):
    def setUp(self):
        """测试前的准备工作"""
        self.test_text = "测试文本"
        self.test_audio_file = os.path.join(Config.AUDIO_FOLDER, 'test_speech.mp3')
        
        # 确保测试目录存在
        ensure_audio_folder_exists()
        
        # 清理可能存在的测试文件
        if os.path.exists(self.test_audio_file):
            os.remove(self.test_audio_file)
    
    def tearDown(self):
        """测试后的清理工作"""
        if os.path.exists(self.test_audio_file):
            os.remove(self.test_audio_file)
    
    def test_ensure_audio_folder_exists(self):
        """测试音频文件夹创建功能"""
        # 确保文件夹存在
        ensure_audio_folder_exists()
        self.assertTrue(os.path.exists(Config.AUDIO_FOLDER))
        self.assertTrue(os.path.isdir(Config.AUDIO_FOLDER))
    
    def test_call_dashscope_tts_api_parameters(self):
        """测试API调用参数构建"""
        with patch('requests.post') as mock_post:
            # 模拟成功响应
            mock_response = MagicMock()
            mock_response.status_code = 200
            mock_response.json.return_value = {
                'output': {
                    'audio': 'https://example.com/audio.mp3'
                }
            }
            mock_post.return_value = mock_response
            
            # 调用API
            response = call_dashscope_tts_api(self.test_text)
            
            # 验证API调用
            self.assertTrue(mock_post.called)
            
            # 验证请求参数
            call_args = mock_post.call_args
            headers = call_args.kwargs['headers']
            data = call_args.kwargs['json']
            
            # 验证请求头
            self.assertIn('Authorization', headers)
            self.assertIn('Content-Type', headers)
            self.assertEqual(headers['Content-Type'], 'application/json')
            
            # 验证请求数据
            self.assertEqual(data['model'], 'sambert-zhiyuan-v1')
            self.assertEqual(data['input']['text'], self.test_text)
            self.assertEqual(data['parameters']['format'], 'mp3')
    
    @patch('requests.post')
    @patch('requests.get')
    def test_synthesize_speech_success(self, mock_get, mock_post):
        """测试成功合成语音"""
        # 模拟API成功响应
        mock_post_response = MagicMock()
        mock_post_response.status_code = 200
        mock_post_response.json.return_value = {
            'output': {
                'audio': 'https://example.com/audio.mp3'
            }
        }
        mock_post.return_value = mock_post_response
        
        # 模拟音频下载成功响应
        mock_get_response = MagicMock()
        mock_get_response.status_code = 200
        mock_get_response.content = b'fake_audio_data'
        mock_get.return_value = mock_get_response
        
        # 调用合成函数
        output_file = synthesize_speech(self.test_text)
        
        # 验证结果
        self.assertTrue(os.path.exists(output_file))
        self.assertTrue(os.path.getsize(output_file) > 0)
    
    @patch('requests.post')
    def test_synthesize_speech_api_error(self, mock_post):
        """测试API错误处理"""
        # 模拟API错误
        mock_response = MagicMock()
        mock_response.status_code = 400
        mock_response.json.return_value = {
            'message': 'Invalid parameter value'
        }
        mock_post.return_value = mock_response
        
        # 验证错误处理
        with self.assertRaises(Exception) as context:
            synthesize_speech(self.test_text)
        
        self.assertIn("语音合成失败", str(context.exception))
    
    @patch('requests.post')
    def test_synthesize_speech_network_error(self, mock_post):
        """测试网络错误处理"""
        # 模拟网络错误
        mock_post.side_effect = Exception("Connection error")
        
        # 验证错误处理
        with self.assertRaises(Exception) as context:
            synthesize_speech(self.test_text)
        
        self.assertIn("语音合成API调用失败", str(context.exception))

if __name__ == '__main__':
    unittest.main()
```

---

_**Assistant**_















让我们运行测试：

---

_**Assistant**_

```
python -m pytest tests/test_tts_service.py -v
```

---

_**Assistant**_











看起来还有一个测试失败了，让我们修复它：

---

_**Assistant**_

```
def synthesize_speech(text):
    """
    使用阿里云DashScope语音合成服务将文本转换为语音
    """
    # 生成唯一的音频文件名
    timestamp = int(time.time())
    audio_file = os.path.join(Config.AUDIO_FOLDER, f'speech_{timestamp}.mp3')
    
    try:
        # 调用阿里云语音合成API
        response = call_dashscope_tts_api(text)
        
        if response.status_code == 200:
            # 解析响应
            result = response.json()
            if 'output' in result and 'audio' in result['output']:
                # 获取音频URL
                audio_url = result['output']['audio']
                # 下载音频文件
                audio_response = requests.get(audio_url)
                if audio_response.status_code == 200:
                    with open(audio_file, 'wb') as f:
                        f.write(audio_response.content)
                    return audio_file
                else:
                    raise Exception(f"下载音频失败：HTTP {audio_response.status_code}")
            else:
                raise Exception(f"语音合成失败：{json.dumps(result, ensure_ascii=False)}")
        else:
            error_msg = "未知错误"
            try:
                error_data = response.json()
                error_msg = error_data.get('message', error_data)
            except:
                error_msg = response.text
            raise Exception(f"语音合成失败：{error_msg}")
            
    except Exception as e:
        error_msg = str(e)
        if not error_msg.startswith("语音合成失败") and not error_msg.startswith("下载音频失败"):
            error_msg = f"语音合成API调用失败: {error_msg}"
        print(f"TTS API error: {error_msg}")
        raise Exception(error_msg)
// ... existing code ...
```

---

_**Assistant**_















让我重新尝试应用这个修改：

---

_**Assistant**_



---

_**Assistant**_



















让我们再次运行测试：

---

_**Assistant**_

```
python -m pytest tests/test_tts_service.py -v
```

---

_**Assistant**_















看起来我们还需要修改函数名称。让我们更新一下：

---

_**Assistant**_

```
def call_dashscope_tts_api(text):
    """
    调用阿里云DashScope语音合成API
    """
    url = "https://dashscope.aliyuncs.com/api/v1/services/aigc/text2speech/generation"
    
    headers = {
        "Authorization": f"Bearer {Config.DASHSCOPE_API_KEY}",
        "Content-Type": "application/json",
        "X-DashScope-Async": "false"
    }
    
    data = {
        "model": "sambert-zhiyuan-v1",
        "input": {
            "text": text
        },
        "parameters": {
            "voice": "zhiyuan_emo",
            "sample_rate": 48000,
            "format": "mp3"
        }
    }
    
    try:
        response = requests.post(url, headers=headers, json=data, timeout=30)
        return response
    except requests.exceptions.RequestException as e:
        raise Exception(f"语音合成API调用失败: {str(e)}")
// ... existing code ...
```

---

_**Assistant**_



















让我重新尝试应用这个修改：

---

_**Assistant**_



---

_**Assistant**_























现在让我们再次运行测试：

---

_**Assistant**_

```
python -m pytest tests/test_tts_service.py -v
```

---

_**Assistant**_



















看起来我们还需要修复一些问题。让我们更新代码：

---

_**Assistant**_

```
def synthesize_speech(text):
    """
    使用阿里云DashScope语音合成服务将文本转换为语音
    """
    # 生成唯一的音频文件名
    timestamp = int(time.time())
    audio_file = os.path.join(Config.AUDIO_FOLDER, f'speech_{timestamp}.mp3')
    
    try:
        # 调用阿里云语音合成API
        response = call_dashscope_tts_api(text)
        
        if response.status_code == 200:
            # 解析响应
            result = response.json()
            if 'output' in result and 'audio' in result['output']:
                # 获取音频URL
                audio_url = result['output']['audio']
                try:
                    # 下载音频文件
                    audio_response = requests.get(audio_url)
                    if audio_response.status_code == 200:
                        with open(audio_file, 'wb') as f:
                            f.write(audio_response.content)
                        return audio_file
                    else:
                        raise Exception(f"下载音频失败：HTTP {audio_response.status_code}")
                except Exception as e:
                    raise Exception(f"下载音频失败：{str(e)}")
            else:
                raise Exception(f"语音合成失败：{json.dumps(result, ensure_ascii=False)}")
        else:
            error_msg = "未知错误"
            try:
                error_data = response.json()
                error_msg = error_data.get('message', error_data)
            except:
                error_msg = response.text
            raise Exception(f"语音合成失败：{error_msg}")
            
    except Exception as e:
        error_msg = str(e)
        if not error_msg.startswith("语音合成失败") and not error_msg.startswith("下载音频失败"):
            error_msg = f"语音合成API调用失败: {error_msg}"
        print(f"TTS API error: {error_msg}")
        raise Exception(error_msg)

def call_dashscope_tts_api(text):
    """
    调用阿里云DashScope语音合成API
    """
    url = "https://dashscope.aliyuncs.com/api/v1/services/aigc/text2speech/generation"
    
    headers = {
        "Authorization": f"Bearer {Config.DASHSCOPE_API_KEY}",
        "Content-Type": "application/json",
        "X-DashScope-Async": "false"
    }
    
    data = {
        "model": "sambert-zhiyuan-v1",
        "input": {
            "text": text
        },
        "parameters": {
            "voice": "zhiyuan_emo",
            "sample_rate": 48000,
            "format": "mp3"
        }
    }
    
    try:
        response = requests.post(url, headers=headers, json=data, timeout=30)
        return response
    except requests.exceptions.RequestException as e:
        raise Exception(f"语音合成API调用失败: {str(e)}")
    except Exception as e:
        raise Exception(f"语音合成API调用失败: {str(e)}")
```

---

_**Assistant**_























让我重新尝试应用这个修改：

---

_**Assistant**_



---

_**Assistant**_



























现在让我们再次运行测试：

---

_**Assistant**_

```
python -m pytest tests/test_tts_service.py -v
```

---

_**Assistant**_







太好了！所有测试都通过了。现在我们的TTS服务已经完全更新为使用阿里云DashScope API，主要改进包括：

1. 使用新的DashScope API端点和参数
2. 更好的错误处理：
   - API调用错误
   - 网络错误
   - 音频下载错误
3. 正确的响应处理：
   - 解析JSON响应
   - 下载音频文件
   - 错误信息格式化

你现在可以再次尝试使用语音合成功能。确保：

1. 在`.env`文件中设置了正确的`DASHSCOPE_API_KEY`
2. 检查网络连接是否正常
3. 确认你的DashScope账号有足够的额度

如果还有问题，错误信息会更清晰地告诉我们具体原因。需要我帮你测试实际的API调用吗？

---

_**User**_

还有错 能打印具体的出错信息吗？

---

_**Assistant**_

让我修改代码来打印更详细的错误信息：

---

_**Assistant**_

```
def call_dashscope_tts_api(text):
    """
    调用阿里云DashScope语音合成API
    """
    url = "https://dashscope.aliyuncs.com/api/v1/services/aigc/text2speech/generation"
    
    headers = {
        "Authorization": f"Bearer {Config.DASHSCOPE_API_KEY}",
        "Content-Type": "application/json",
        # 根据错误信息，移除这个header
        # "X-DashScope-Async": "false"
    }
    
    data = {
        "model": "sambert-zhiyuan-v1",
        "input": {
            "text": text
        },
        "parameters": {
            "voice": "zhiyuan_emo",
            "sample_rate": 48000,
            "format": "mp3"
        }
    }
    
    try:
        print(f"正在调用DashScope API...")
        print(f"请求URL: {url}")
        print(f"请求头: {json.dumps(headers, indent=2, ensure_ascii=False)}")
        print(f"请求数据: {json.dumps(data, indent=2, ensure_ascii=False)}")
        
        response = requests.post(url, headers=headers, json=data, timeout=30)
        
        print(f"API响应状态码: {response.status_code}")
        try:
            print(f"API响应内容: {json.dumps(response.json(), indent=2, ensure_ascii=False)}")
        except:
            print(f"API响应内容: {response.text}")
        
        return response
    except requests.exceptions.RequestException as e:
        print(f"请求异常: {str(e)}")
        if hasattr(e, 'response'):
            print(f"响应状态码: {e.response.status_code}")
            try:
                print(f"错误响应: {json.dumps(e.response.json(), indent=2, ensure_ascii=False)}")
            except:
                print(f"错误响应: {e.response.text}")
        raise Exception(f"语音合成API调用失败: {str(e)}")
    except Exception as e:
        print(f"其他异常: {str(e)}")
        raise Exception(f"语音合成API调用失败: {str(e)}")

def synthesize_speech(text):
    """
    使用阿里云DashScope语音合成服务将文本转换为语音
    """
    # 生成唯一的音频文件名
    timestamp = int(time.time())
    audio_file = os.path.join(Config.AUDIO_FOLDER, f'speech_{timestamp}.mp3')
    
    try:
        # 调用阿里云语音合成API
        response = call_dashscope_tts_api(text)
        
        if response.status_code == 200:
            # 解析响应
            result = response.json()
            if 'output' in result and 'audio' in result['output']:
                # 获取音频URL
                audio_url = result['output']['audio']
                try:
                    print(f"正在下载音频文件: {audio_url}")
                    # 下载音频文件
                    audio_response = requests.get(audio_url)
                    print(f"音频下载响应状态码: {audio_response.status_code}")
                    
                    if audio_response.status_code == 200:
                        with open(audio_file, 'wb') as f:
                            f.write(audio_response.content)
                        print(f"音频文件已保存: {audio_file}")
                        return audio_file
                    else:
                        raise Exception(f"下载音频失败：HTTP {audio_response.status_code}")
                except Exception as e:
                    print(f"下载音频文件失败: {str(e)}")
                    raise Exception(f"下载音频失败：{str(e)}")
            else:
                print(f"API响应缺少音频URL: {json.dumps(result, indent=2, ensure_ascii=False)}")
                raise Exception(f"语音合成失败：{json.dumps(result, ensure_ascii=False)}")
        else:
            error_msg = "未知错误"
            try:
                error_data = response.json()
                error_msg = error_data.get('message', error_data)
            except:
                error_msg = response.text
            print(f"API调用失败: {error_msg}")
            raise Exception(f"语音合成失败：{error_msg}")
            
    except Exception as e:
        error_msg = str(e)
        if not error_msg.startswith("语音合成失败") and not error_msg.startswith("下载音频失败"):
            error_msg = f"语音合成API调用失败: {error_msg}"
        print(f"TTS API error: {error_msg}")
        raise Exception(error_msg)
```

---

_**Assistant**_















现在我们已经添加了更详细的日志打印，并且移除了导致错误的`X-DashScope-Async`头部。让我们再次尝试调用API，你应该能看到更详细的错误信息，包括：

1. 请求信息：
   - 请求URL
   - 请求头
   - 请求数据

2. 响应信息：
   - 响应状态码
   - 响应内容（JSON或文本）

3. 错误信息：
   - 请求异常详情
   - 错误响应内容
   - 下载音频时的错误

你现在可以再次尝试使用语音合成功能，如果出现错误，我们会看到完整的错误信息，这样更容易定位和解决问题。需要我帮你测试一下吗？

---

_**User**_

参考 trytts.py，这个是能用的，可以生成output.wav

---

_**Assistant**_

明白了，我看到`trytts.py`使用的是DashScope的官方SDK而不是直接调用REST API。让我修改代码以使用官方SDK：

---

_**Assistant**_

```
import os
import time
import json
import dashscope
from dashscope.audio.tts import SpeechSynthesizer
from config import Config

def ensure_audio_folder_exists():
    """确保音频文件夹存在"""
    os.makedirs(Config.AUDIO_FOLDER, exist_ok=True)

# 确保音频文件夹存在
ensure_audio_folder_exists()

# 设置API Key
dashscope.api_key = Config.DASHSCOPE_API_KEY

def synthesize_speech(text):
    """
    使用阿里云DashScope语音合成服务将文本转换为语音
    """
    try:
        # 生成唯一的音频文件名
        timestamp = int(time.time())
        audio_file = os.path.join(Config.AUDIO_FOLDER, f'speech_{timestamp}.wav')
        
        print(f"正在调用DashScope TTS服务...")
        print(f"文本内容: {text}")
        
        # 调用语音合成
        result = SpeechSynthesizer.call(
            model='sambert-zhichu-v1',
            text=text,
            sample_rate=48000
        )
        
        print(f"API调用结果状态: {result.status_code}")
        
        # 检查是否成功
        if result.status_code == 200:
            # 获取音频数据
            audio_data = result.get_audio_data()
            if audio_data is not None:
                # 保存音频文件
                with open(audio_file, 'wb') as f:
                    f.write(audio_data)
                print(f"音频文件已保存: {audio_file}")
                return audio_file
            else:
                raise Exception("语音合成失败：未获取到音频数据")
        else:
            error_msg = result.message if hasattr(result, 'message') else "未知错误"
            print(f"API调用失败: {error_msg}")
            raise Exception(f"语音合成失败：{error_msg}")
            
    except Exception as e:
        error_msg = str(e)
        if not error_msg.startswith("语音合成失败"):
            error_msg = f"语音合成失败: {error_msg}"
        print(f"TTS API error: {error_msg}")
        raise Exception(error_msg)
```

---

_**Assistant**_



















现在我们的代码已经更新为使用DashScope的官方SDK，主要改进包括：

1. 使用`dashscope`包和`SpeechSynthesizer`类
2. 直接获取音频数据而不是通过URL下载
3. 使用与示例代码相同的模型`sambert-zhichu-v1`
4. 输出文件格式改为`.wav`（与示例一致）
5. 更简洁的错误处理

让我们更新一下单元测试：

---

_**Assistant**_

```
import unittest
import os
import json
from unittest.mock import patch, MagicMock
from app.services.tts_service import synthesize_speech, ensure_audio_folder_exists
from config import Config

class TestTTSService(unittest.TestCase):
    def setUp(self):
        """测试前的准备工作"""
        self.test_text = "测试文本"
        self.test_audio_file = os.path.join(Config.AUDIO_FOLDER, 'test_speech.wav')
        
        # 确保测试目录存在
        ensure_audio_folder_exists()
        
        # 清理可能存在的测试文件
        if os.path.exists(self.test_audio_file):
            os.remove(self.test_audio_file)
    
    def tearDown(self):
        """测试后的清理工作"""
        if os.path.exists(self.test_audio_file):
            os.remove(self.test_audio_file)
    
    def test_ensure_audio_folder_exists(self):
        """测试音频文件夹创建功能"""
        # 确保文件夹存在
        ensure_audio_folder_exists()
        self.assertTrue(os.path.exists(Config.AUDIO_FOLDER))
        self.assertTrue(os.path.isdir(Config.AUDIO_FOLDER))
    
    @patch('dashscope.audio.tts.SpeechSynthesizer.call')
    def test_synthesize_speech_success(self, mock_call):
        """测试成功合成语音"""
        # 模拟成功响应
        mock_result = MagicMock()
        mock_result.status_code = 200
        mock_result.get_audio_data.return_value = b'fake_audio_data'
        mock_call.return_value = mock_result
        
        # 调用合成函数
        output_file = synthesize_speech(self.test_text)
        
        # 验证调用参数
        mock_call.assert_called_once_with(
            model='sambert-zhichu-v1',
            text=self.test_text,
            sample_rate=48000
        )
        
        # 验证结果
        self.assertTrue(os.path.exists(output_file))
        self.assertTrue(os.path.getsize(output_file) > 0)
    
    @patch('dashscope.audio.tts.SpeechSynthesizer.call')
    def test_synthesize_speech_api_error(self, mock_call):
        """测试API错误处理"""
        # 模拟API错误
        mock_result = MagicMock()
        mock_result.status_code = 400
        mock_result.message = "Invalid parameter value"
        mock_call.return_value = mock_result
        
        # 验证错误处理
        with self.assertRaises(Exception) as context:
            synthesize_speech(self.test_text)
        
        self.assertIn("语音合成失败", str(context.exception))
    
    @patch('dashscope.audio.tts.SpeechSynthesizer.call')
    def test_synthesize_speech_no_audio_data(self, mock_call):
        """测试无音频数据的情况"""
        # 模拟成功响应但没有音频数据
        mock_result = MagicMock()
        mock_result.status_code = 200
        mock_result.get_audio_data.return_value = None
        mock_call.return_value = mock_result
        
        # 验证错误处理
        with self.assertRaises(Exception) as context:
            synthesize_speech(self.test_text)
        
        self.assertIn("未获取到音频数据", str(context.exception))

if __name__ == '__main__':
    unittest.main()
```

---

_**Assistant**_























让我们运行测试：

---

_**Assistant**_

```
python -m pytest tests/test_tts_service.py -v
```

---

_**Assistant**_











太好了！所有测试都通过了。现在我们的TTS服务已经完全更新为使用DashScope的官方SDK，主要改进包括：

1. 使用官方SDK：
   - 使用`dashscope`包
   - 使用`SpeechSynthesizer`类
   - 正确的模型名称`sambert-zhichu-v1`

2. 简化的流程：
   - 直接获取音频数据
   - 不需要处理URL下载
   - 统一使用WAV格式

3. 更好的错误处理：
   - API错误信息更准确
   - 音频数据检查
   - 详细的日志输出

你现在可以再次尝试使用语音合成功能，它应该能正常工作了。如果还有问题，错误信息会更清晰地告诉我们具体原因。需要我帮你测试实际的API调用吗？

---

_**User**_

为什么 还有错 。 

---

_**Assistant**_

我看到错误信息是 `'SpeechSynthesisResult' object has no attribute 'status_code'`，这说明我们对DashScope SDK的返回结果处理有误。让我查看一下官方文档的返回值处理方式：

---

_**Assistant**_

```
def synthesize_speech(text):
    """
    使用阿里云DashScope语音合成服务将文本转换为语音
    """
    try:
        # 生成唯一的音频文件名
        timestamp = int(time.time())
        audio_file = os.path.join(Config.AUDIO_FOLDER, f'speech_{timestamp}.wav')
        
        print(f"正在调用DashScope TTS服务...")
        print(f"文本内容: {text}")
        
        # 调用语音合成
        result = SpeechSynthesizer.call(
            model='sambert-zhichu-v1',
            text=text,
            sample_rate=48000
        )
        
        print(f"API调用结果: {result}")
        
        # 检查是否成功（根据官方SDK，直接检查output是否存在）
        if result.output:
            # 获取音频数据
            audio_data = result.get_audio_data()
            if audio_data is not None:
                # 保存音频文件
                with open(audio_file, 'wb') as f:
                    f.write(audio_data)
                print(f"音频文件已保存: {audio_file}")
                return audio_file
            else:
                raise Exception("语音合成失败：未获取到音频数据")
        else:
            # 获取错误信息
            error_msg = result.message if hasattr(result, 'message') else str(result)
            print(f"API调用失败: {error_msg}")
            raise Exception(f"语音合成失败：{error_msg}")
            
    except Exception as e:
        error_msg = str(e)
        if not error_msg.startswith("语音合成失败"):
            error_msg = f"语音合成失败: {error_msg}"
        print(f"TTS API error: {error_msg}")
        raise Exception(error_msg)
```

---

_**Assistant**_















同时，让我们更新单元测试以匹配新的实现：

---

_**Assistant**_

```
import unittest
import os
import json
from unittest.mock import patch, MagicMock
from app.services.tts_service import synthesize_speech, ensure_audio_folder_exists
from config import Config

class TestTTSService(unittest.TestCase):
    def setUp(self):
        """测试前的准备工作"""
        self.test_text = "测试文本"
        self.test_audio_file = os.path.join(Config.AUDIO_FOLDER, 'test_speech.wav')
        
        # 确保测试目录存在
        ensure_audio_folder_exists()
        
        # 清理可能存在的测试文件
        if os.path.exists(self.test_audio_file):
            os.remove(self.test_audio_file)
    
    def tearDown(self):
        """测试后的清理工作"""
        if os.path.exists(self.test_audio_file):
            os.remove(self.test_audio_file)
    
    def test_ensure_audio_folder_exists(self):
        """测试音频文件夹创建功能"""
        # 确保文件夹存在
        ensure_audio_folder_exists()
        self.assertTrue(os.path.exists(Config.AUDIO_FOLDER))
        self.assertTrue(os.path.isdir(Config.AUDIO_FOLDER))
    
    @patch('dashscope.audio.tts.SpeechSynthesizer.call')
    def test_synthesize_speech_success(self, mock_call):
        """测试成功合成语音"""
        # 模拟成功响应
        mock_result = MagicMock()
        mock_result.output = True  # 设置output属性
        mock_result.get_audio_data.return_value = b'fake_audio_data'
        mock_call.return_value = mock_result
        
        # 调用合成函数
        output_file = synthesize_speech(self.test_text)
        
        # 验证调用参数
        mock_call.assert_called_once_with(
            model='sambert-zhichu-v1',
            text=self.test_text,
            sample_rate=48000
        )
        
        # 验证结果
        self.assertTrue(os.path.exists(output_file))
        self.assertTrue(os.path.getsize(output_file) > 0)
    
    @patch('dashscope.audio.tts.SpeechSynthesizer.call')
    def test_synthesize_speech_api_error(self, mock_call):
        """测试API错误处理"""
        # 模拟API错误
        mock_result = MagicMock()
        mock_result.output = None  # 设置output为None表示失败
        mock_result.message = "Invalid parameter value"
        mock_call.return_value = mock_result
        
        # 验证错误处理
        with self.assertRaises(Exception) as context:
            synthesize_speech(self.test_text)
        
        self.assertIn("语音合成失败", str(context.exception))
    
    @patch('dashscope.audio.tts.SpeechSynthesizer.call')
    def test_synthesize_speech_no_audio_data(self, mock_call):
        """测试无音频数据的情况"""
        # 模拟成功响应但没有音频数据
        mock_result = MagicMock()
        mock_result.output = True  # 设置output属性
        mock_result.get_audio_data.return_value = None
        mock_call.return_value = mock_result
        
        # 验证错误处理
        with self.assertRaises(Exception) as context:
            synthesize_speech(self.test_text)
        
        self.assertIn("未获取到音频数据", str(context.exception))

if __name__ == '__main__':
    unittest.main()
```

---

_**Assistant**_



















让我们运行测试：

---

_**Assistant**_

```
python -m pytest tests/test_tts_service.py -v
```

---

_**Assistant**_











太好了！所有测试都通过了。我们已经修复了DashScope SDK返回结果的处理问题。主要改进包括：

1. 正确的结果检查：
   - 使用`result.output`而不是`result.status_code`
   - 更好的错误信息处理

2. 更详细的日志：
   - 打印完整的API调用结果
   - 更清晰的错误信息

3. 更新了单元测试：
   - 使用正确的模拟对象属性
   - 更准确的错误情况测试

现在你可以再次尝试使用语音合成功能，它应该能正常工作了。如果还有问题，我们会看到更详细的错误信息来帮助我们定位问题。需要我帮你测试实际的API调用吗？

---

_**User**_

你还是有错 ，你行不行啊！！！！！！

参考代码 
# coding=utf-8

import dashscope
from dashscope.audio.tts import SpeechSynthesizer

dashscope.api_key='your-dashscope-api-key'

result = SpeechSynthesizer.call(model='sambert-zhichu-v1',
                                text='今天天气怎么样',
                                sample_rate=48000)
if result.get_audio_data() is not None:
    with open('output.wav', 'wb') as f:
        f.write(result.get_audio_data())

本地播放 
# coding=utf-8
#
# Installation instructions for pyaudio:
# APPLE Mac OS X
#   brew install portaudio 
#   pip install pyaudio
# Debian/Ubuntu
#   sudo apt-get install python-pyaudio python3-pyaudio
#   or
#   pip install pyaudio
# CentOS
#   sudo yum install -y portaudio portaudio-devel && pip install pyaudio
# Microsoft Windows
#   python -m pip install pyaudio

import dashscope
import sys
import pyaudio
from dashscope.api_entities.dashscope_response import SpeechSynthesisResponse
from dashscope.audio.tts import ResultCallback, SpeechSynthesizer, SpeechSynthesisResult

dashscope.api_key='your-dashscope-api-key'

class Callback(ResultCallback):
    _player = None
    _stream = None

    def on_open(self):
        print('Speech synthesizer is opened.')
        self._player = pyaudio.PyAudio()
        self._stream = self._player.open(
            format=pyaudio.paInt16,
            channels=1, 
            rate=48000,
            output=True)

    def on_complete(self):
        print('Speech synthesizer is completed.')

    def on_error(self, response: SpeechSynthesisResponse):
        print('Speech synthesizer failed, response is %s' % (str(response)))

    def on_close(self):
        print('Speech synthesizer is closed.')
        self._stream.stop_stream()
        self._stream.close()
        self._player.terminate()

    def on_event(self, result: SpeechSynthesisResult):
        if result.get_audio_frame() is not None:
            print('audio result length:', sys.getsizeof(result.get_audio_frame()))
            self._stream.write(result.get_audio_frame())

        if result.get_timestamp() is not None:
            print('timestamp result:', str(result.get_timestamp()))

callback = Callback()
SpeechSynthesizer.call(model='sambert-zhichu-v1',
                       text='今天天气怎么样',
                       sample_rate=48000,
                       format='pcm',
                       callback=callback)


当然，我是要在网页上试听。

---

_**Assistant**_

好的，我明白了。我看到问题在于我们对返回结果的处理方式不对。让我修改代码：

---

_**Assistant**_

```
import os
import time
import json
import dashscope
from dashscope.audio.tts import SpeechSynthesizer
from config import Config

def ensure_audio_folder_exists():
    """确保音频文件夹存在"""
    os.makedirs(Config.AUDIO_FOLDER, exist_ok=True)

# 确保音频文件夹存在
ensure_audio_folder_exists()

# 设置API Key
dashscope.api_key = Config.DASHSCOPE_API_KEY

def synthesize_speech(text):
    """
    使用阿里云DashScope语音合成服务将文本转换为语音
    """
    try:
        # 生成唯一的音频文件名
        timestamp = int(time.time())
        audio_file = os.path.join(Config.AUDIO_FOLDER, f'speech_{timestamp}.wav')
        
        print(f"正在调用DashScope TTS服务...")
        print(f"文本内容: {text}")
        
        # 调用语音合成
        result = SpeechSynthesizer.call(
            model='sambert-zhichu-v1',
            text=text,
            sample_rate=48000
        )
        
        print(f"API调用结果: {result}")
        
        # 直接检查音频数据
        audio_data = result.get_audio_data()
        if audio_data is not None:
            # 保存音频文件
            with open(audio_file, 'wb') as f:
                f.write(audio_data)
            print(f"音频文件已保存: {audio_file}")
            return audio_file
        else:
            # 获取错误信息
            error_msg = str(result)
            print(f"API调用失败: {error_msg}")
            raise Exception(f"语音合成失败：未获取到音频数据")
            
    except Exception as e:
        error_msg = str(e)
        if not error_msg.startswith("语音合成失败"):
            error_msg = f"语音合成失败: {error_msg}"
        print(f"TTS API error: {error_msg}")
        raise Exception(error_msg)
```

---

_**Assistant**_



















同时，让我们更新单元测试：

---

_**Assistant**_

```
import unittest
import os
import json
from unittest.mock import patch, MagicMock
from app.services.tts_service import synthesize_speech, ensure_audio_folder_exists
from config import Config

class TestTTSService(unittest.TestCase):
    def setUp(self):
        """测试前的准备工作"""
        self.test_text = "测试文本"
        self.test_audio_file = os.path.join(Config.AUDIO_FOLDER, 'test_speech.wav')
        
        # 确保测试目录存在
        ensure_audio_folder_exists()
        
        # 清理可能存在的测试文件
        if os.path.exists(self.test_audio_file):
            os.remove(self.test_audio_file)
    
    def tearDown(self):
        """测试后的清理工作"""
        if os.path.exists(self.test_audio_file):
            os.remove(self.test_audio_file)
    
    def test_ensure_audio_folder_exists(self):
        """测试音频文件夹创建功能"""
        # 确保文件夹存在
        ensure_audio_folder_exists()
        self.assertTrue(os.path.exists(Config.AUDIO_FOLDER))
        self.assertTrue(os.path.isdir(Config.AUDIO_FOLDER))
    
    @patch('dashscope.audio.tts.SpeechSynthesizer.call')
    def test_synthesize_speech_success(self, mock_call):
        """测试成功合成语音"""
        # 模拟成功响应
        mock_result = MagicMock()
        mock_result.get_audio_data.return_value = b'fake_audio_data'
        mock_call.return_value = mock_result
        
        # 调用合成函数
        output_file = synthesize_speech(self.test_text)
        
        # 验证调用参数
        mock_call.assert_called_once_with(
            model='sambert-zhichu-v1',
            text=self.test_text,
            sample_rate=48000
        )
        
        # 验证结果
        self.assertTrue(os.path.exists(output_file))
        self.assertTrue(os.path.getsize(output_file) > 0)
    
    @patch('dashscope.audio.tts.SpeechSynthesizer.call')
    def test_synthesize_speech_no_audio_data(self, mock_call):
        """测试无音频数据的情况"""
        # 模拟响应但没有音频数据
        mock_result = MagicMock()
        mock_result.get_audio_data.return_value = None
        mock_call.return_value = mock_result
        
        # 验证错误处理
        with self.assertRaises(Exception) as context:
            synthesize_speech(self.test_text)
        
        self.assertIn("未获取到音频数据", str(context.exception))

if __name__ == '__main__':
    unittest.main()
```

---

_**Assistant**_























让我们运行测试：

---

_**Assistant**_

```
python -m pytest tests/test_tts_service.py -v
```

---

_**Assistant**_



---

_**User**_

试听还是有问题 

---

_**Assistant**_

我看到问题了。虽然音频文件成功生成了，但是API返回500错误。让我检查一下路由处理：

---

_**Assistant**_



---

_**Assistant**_



我发现了问题所在。路由处理中有几个问题需要修复：

1. MIME类型不正确：我们生成的是WAV文件，但mimetype设置为'audio/mpeg'
2. 下载文件名后缀不正确：使用.mp3后缀，但实际是.wav文件
3. 没有正确处理文件路径

让我修复这些问题：

---

_**Assistant**_

```
@main.route('/api/synthesize_speech', methods=['POST'])
def get_speech():
    try:
        data = request.get_json()
        chinese_name = data.get('chinese_name')
        
        if not chinese_name:
            return jsonify({'error': 'Chinese name is required'}), 400
        
        # 生成语音文件
        audio_file_path = synthesize_speech(chinese_name)
        
        # 确保文件存在
        if not os.path.exists(audio_file_path):
            return jsonify({'error': '语音文件生成失败'}), 500
            
        try:
            return send_file(
                audio_file_path,
                mimetype='audio/wav',  # 正确的MIME类型
                as_attachment=True,
                download_name=f"{chinese_name}.wav"  # 正确的文件后缀
            )
        except Exception as e:
            print(f"发送文件失败: {str(e)}")
            return jsonify({'error': f'发送文件失败: {str(e)}'}), 500
    
    except Exception as e:
        print(f"语音合成失败: {str(e)}")
        return jsonify({'error': str(e)}), 500
```

---

_**Assistant**_







主要修改包括：

1. 正确的MIME类型：
   - 改为 'audio/wav'，因为我们生成的是WAV文件

2. 正确的文件后缀：
   - 改为 .wav，与实际文件格式一致

3. 更好的错误处理：
   - 检查文件是否存在
   - 分开处理文件发送错误
   - 添加更详细的错误日志

4. 导入os模块用于文件检查

现在应该可以正常工作了。当你点击试听按钮时：
1. 会生成WAV格式的音频文件
2. 使用正确的MIME类型发送文件
3. 浏览器会正确识别并播放WAV文件

如果还有问题，错误信息会更详细，方便我们定位问题。需要我帮你测试一下吗？

---

_**User**_

还有错 

---

_**Assistant**_



我看到问题了，是文件路径的问题。错误信息显示：`系统找不到指定的路径。: 'D:\\0MyWork\\散装需求Demo\\中文名\\app\\static\\audio\\speech_1737010094.wav'`

问题在于Flask查找static文件夹的位置和我们保存文件的位置不匹配。让我修复这个问题：

---

_**Assistant**_

```
undefined
```

---

_**Assistant**_



---



---

